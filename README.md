# llm-txtfile-chatting

# make a python env
# install numpy , ollama and llama3 (you can use any llm just make the changes in the main.py file accordingly)
# that should help you run the project
# (this will run according to your cpu and gpu capabilities)
